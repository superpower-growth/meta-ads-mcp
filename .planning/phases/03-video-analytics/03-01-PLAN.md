---
phase: 03-video-analytics
plan: 01
type: execute
---

<objective>
Create MCP tool for querying video completion metrics with percentile breakdowns.

Purpose: Enable conversational analysis of video ad engagement by exposing completion percentiles (25%, 50%, 75%, 95%, 100%), ThruPlay counts, and total video plays through MCP interface.

Output: get-video-performance MCP tool that queries video-specific metrics at campaign/adset/ad levels, parses array responses using parseVideoMetrics utility, and returns formatted completion funnel data.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-metrics-query/DISCOVERY.md
@.planning/phases/02-core-metrics-query/02-01-SUMMARY.md

# Key files
@src/meta/metrics.ts
@src/lib/parsers.ts
@src/tools/get-campaign-performance.ts
@src/tools/index.ts
@src/index.ts

**Tech stack available:** MetricsService, parseVideoMetrics utility, established tool patterns

**Established patterns:**
- Tool structure: Zod schema, manual inputSchema, implementation function
- MetricsService for insights queries
- Parser utilities for complex array fields
- Pretty-printed JSON responses

**Constraining decisions:**
- Plan 02-01: parseVideoMetrics() handles video percentile arrays
- Plan 02-02: Manual inputSchema pattern (no zod-to-json-schema)
- DISCOVERY.md Section "Video Completion Metrics": video_pXX_watched_actions return arrays
- DISCOVERY.md: video_thruplay_watched_actions = 15s or complete view
- DISCOVERY.md: Must extract first element's value from action arrays

**Issues being addressed:** None
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create get-video-performance tool definition and schema</name>
  <files>src/tools/get-video-performance.ts</files>
  <action>
Create MCP tool for video completion metrics following established patterns.

Zod schema:
```typescript
const schema = z.object({
  dateRange: z.enum(['last_7d', 'last_30d', 'last_90d', 'this_month']).default('last_7d'),
  level: z.enum(['campaign', 'adset', 'ad']).default('campaign'),
  entityId: z.string().optional(), // Campaign/adset/ad ID for filtering
  includeEngagement: z.boolean().default(true) // Include play actions and 2sec views
});
```

Tool definition:
- name: 'get-video-performance'
- description: 'Query video ad completion metrics including 25/50/75/95/100% percentiles, ThruPlay counts, and video play actions'
- inputSchema: Manual JSON schema following 02-02 pattern

Implementation function signature:
```typescript
export async function getVideoPerformance(args: unknown): Promise<string>
```

Video-specific metric fields to request:
- video_p25_watched_actions
- video_p50_watched_actions
- video_p75_watched_actions
- video_p95_watched_actions
- video_p100_watched_actions
- video_thruplay_watched_actions
- video_play_actions (if includeEngagement true)
- video_continuous_2_sec_watched_actions (if includeEngagement true)
- impressions (for context)

Why these fields: DISCOVERY.md Section "Video Completion Metrics" documents these as the standard video engagement funnel. Percentiles show drop-off at each stage.

What to avoid: Don't request non-video metrics here (keep tool focused). Don't hardcode entity IDs. Don't assume video metrics exist for all ads (some ads are static images).
  </action>
  <verify>npm run type-check passes, tool exports definition and implementation function signature</verify>
  <done>Tool definition created with video-specific schema, metric fields identified, implementation skeleton ready</done>
</task>

<task type="auto">
  <name>Task 2: Implement video metrics query and parsing logic</name>
  <files>src/tools/get-video-performance.ts</files>
  <action>
Complete implementation of getVideoPerformance function with array parsing.

Query logic:
1. Initialize MetricsService with account ID
2. Build params:
   ```typescript
   const params = {
     date_preset: args.dateRange,
     level: args.level,
     time_increment: 'all_days'
   };
   ```
3. Request video metric fields (defined in Task 1)
4. Call MetricsService.getAccountInsights(fields, params)
5. If entityId provided, filter results to matching entity
6. For each insight result, parse video metrics:
   - Use parseVideoMetrics(insight) from lib/parsers.ts
   - Extract video_play_actions using parseActions(insight.video_play_actions)
   - Extract video_continuous_2_sec_watched_actions if requested
   - Extract video_thruplay count
7. Calculate derived metrics:
   - Completion rate at each percentile: (pXX / video_play_actions) * 100
   - Drop-off between stages: p25 → p50 → p75 → p95 → p100
8. Format response:
   ```json
   {
     "dateRange": "last_7d",
     "level": "campaign",
     "videos": [
       {
         "id": "...",
         "name": "...",
         "impressions": 12500,
         "completionFunnel": {
           "plays": 5420,
           "2secViews": 4890,
           "25percent": 4102,
           "50percent": 3456,
           "75percent": 2341,
           "95percent": 1523,
           "100percent": 1234,
           "thruplay": 1450
         },
         "completionRates": {
           "25percent": "75.68%",
           "50percent": "63.76%",
           "75percent": "43.18%",
           "95percent": "28.10%",
           "100percent": "22.76%"
         }
       }
     ]
   }
   ```
9. Return JSON.stringify(result, null, 2)

Error handling:
- If no video metrics found, return "No video ad data found for date range"
- If entityId specified but not found, return "{Level} {id} not found"
- Handle missing video metric fields gracefully (some ads are static images)

Why this format: Completion funnel is the core video engagement metric. Drop-off visualization helps identify weak points. Rates as percentages are human-readable for Claude.

What to avoid: Don't fail if video metrics are null (static image ads). Don't calculate rates if plays = 0 (division by zero). Don't mix video and non-video ads in results (filter to only ads with video_play_actions > 0).
  </action>
  <verify>npm run build succeeds, implementation handles array parsing, calculates completion rates correctly, handles missing data</verify>
  <done>Video query logic implemented, parseVideoMetrics integrated, completion funnel formatted, error cases handled</done>
</task>

<task type="auto">
  <name>Task 3: Register video performance tool in MCP server</name>
  <files>src/tools/index.ts, src/index.ts</files>
  <action>
Integrate get-video-performance tool into MCP server.

In src/tools/index.ts:
1. Import getVideoPerformanceTool from './get-video-performance.js'
2. Add to tools array (5 tools total):
   ```typescript
   export const tools: Tool[] = [
     getAccountTool,
     getCampaignPerformanceTool,
     getAdsetPerformanceTool,
     getAdPerformanceTool,
     getVideoPerformanceTool
   ];
   ```

In src/index.ts:
1. Import getVideoPerformance from './tools/get-video-performance.js'
2. Add case to CallToolRequestSchema handler:
   ```typescript
   case 'get-video-performance': {
     const result = await getVideoPerformance(args as any);
     return { content: [{ type: 'text', text: result }] };
   }
   ```

Verification:
- npm run build succeeds
- npm run dev starts without errors
- 5 tools discoverable via MCP protocol

Why this pattern: Consistent with all prior tool registrations. Video performance as separate tool keeps concerns separated.

What to avoid: Don't forget .js extension. Don't modify existing tool handlers.
  </action>
  <verify>npm run build && npm run dev starts successfully, 5 tools registered, no TypeScript errors</verify>
  <done>Video performance tool registered, server operational, video analytics queryable through MCP</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] npm run build succeeds with no TypeScript errors
- [ ] npm run dev starts server without crashes
- [ ] parseVideoMetrics utility correctly extracts percentiles
- [ ] Completion rates calculated correctly (avoid division by zero)
- [ ] Tool handles ads with no video metrics gracefully
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Video completion funnel queryable through MCP
- Completion rates calculated and formatted
- parseVideoMetrics utility properly integrated
- No errors for static (non-video) ads
- Foundation ready for demographic breakdowns (03-02)
</success_criteria>

<output>
After completion, create `.planning/phases/03-video-analytics/03-01-SUMMARY.md`:

# Phase 3 Plan 01: Video Completion Metrics Summary

**[Substantive one-liner - what shipped]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `src/tools/get-video-performance.ts` - Description
- `src/tools/index.ts` - Description
- `src/index.ts` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Deviations from Plan

[Deviations or "None"]

## Next Phase Readiness

Ready for 03-02-PLAN.md (Demographic Breakdowns). Video completion funnel provides engagement baseline. Next plan will add age/gender/platform breakdowns to identify which demographics engage most with video ads.

## Verification Checklist

- [ ] All verification items from plan
</output>
