---
phase: 02-core-metrics-query
plan: 03
type: execute
---

<objective>
Complete Phase 2 by adding ad set and ad level performance query tools to MCP server.

Purpose: Provide granular performance analysis at ad set (targeting/budget groups) and ad (individual creative) levels, enabling Claude to answer questions about specific targeting strategies and creative performance.

Output: Two new MCP tools (get-adset-performance, get-ad-performance) following established patterns from 02-02, registered in MCP server, with full metric support including video and ROAS.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-metrics-query/DISCOVERY.md
@.planning/phases/02-core-metrics-query/02-01-SUMMARY.md
@.planning/phases/02-core-metrics-query/02-02-SUMMARY.md

# Key files from Phase 2
@src/meta/metrics.ts
@src/lib/parsers.ts
@src/tools/get-campaign-performance.ts
@src/tools/index.ts
@src/index.ts

**Tech stack available:** facebook-nodejs-business-sdk@24.0.1, @modelcontextprotocol/sdk@1.25.3, zod@4.3.6, MetricsService, response parsers

**Established patterns:**
- Tool structure: Zod schema, tool definition, implementation function
- MetricsService abstraction for insights queries
- Response formatting: pretty-printed JSON for Claude
- Tool registration: tools/index.ts + index.ts handler

**Constraining decisions:**
- Plan 02-01: MetricsService provides getAccountInsights(fields, params)
- Plan 02-01: Parser utilities for actions, video metrics, ROAS
- Plan 02-02: Manual inputSchema (no zod-to-json-schema)
- Plan 02-02: Client-side filtering for single entity queries
- DISCOVERY.md: level='adset' and level='ad' supported aggregation levels
- DISCOVERY.md: Same metric fields available at all levels

**Issues being addressed:** None
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create get-adset-performance MCP tool</name>
  <files>src/tools/get-adset-performance.ts</files>
  <action>
Create MCP tool for querying ad set performance metrics, following the exact pattern from get-campaign-performance.ts.

Tool definition structure:
1. Define Zod schema:
   ```typescript
   const schema = z.object({
     dateRange: z.enum(['last_7d', 'last_30d', 'last_90d', 'this_month']).default('last_7d'),
     adsetId: z.string().optional(),
     metrics: z.array(z.enum(['impressions', 'clicks', 'spend', 'ctr', 'cpc', 'cpm', 'purchase_roas'])).default(['impressions', 'clicks', 'spend', 'ctr', 'cpc'])
   });
   ```

2. Export tool definition with manual inputSchema (following 02-02 pattern)

3. Export implementation function:
   - Initialize MetricsService with account ID from env.ts
   - Set params.level = 'adset'
   - Call getAccountInsights() with dateRange and metrics
   - If adsetId provided, filter results to matching ad set
   - Parse response using parseRoas() if purchase_roas requested
   - Format as readable JSON with ad set ID, name, period, metrics
   - Return JSON.stringify(result, null, 2)

Error handling:
- Catch MetricsService errors, return formatted message
- If no ad sets found, return "No ad sets found for date range"
- If adsetId specified but not found, return "Ad set {id} not found"

Why this approach: Ad sets are targeting/budget groups, so same metrics as campaigns apply. Level='adset' aggregation documented in DISCOVERY.md.

What to avoid: Don't add new metric types (stick to campaign metrics). Don't implement breakdown support (that's Phase 3).
  </action>
  <verify>npm run type-check passes, tool exports both definition and implementation</verify>
  <done>Tool created following 02-02 pattern, ad set level queries supported, response formatting consistent</done>
</task>

<task type="auto">
  <name>Task 2: Create get-ad-performance MCP tool</name>
  <files>src/tools/get-ad-performance.ts</files>
  <action>
Create MCP tool for querying individual ad creative performance, following the same pattern as Task 1.

Tool definition structure:
1. Define Zod schema (identical to adset schema but with adId parameter):
   ```typescript
   const schema = z.object({
     dateRange: z.enum(['last_7d', 'last_30d', 'last_90d', 'this_month']).default('last_7d'),
     adId: z.string().optional(),
     metrics: z.array(z.enum(['impressions', 'clicks', 'spend', 'ctr', 'cpc', 'cpm', 'purchase_roas'])).default(['impressions', 'clicks', 'spend', 'ctr', 'cpc'])
   });
   ```

2. Export tool definition with manual inputSchema

3. Export implementation function:
   - Initialize MetricsService
   - Set params.level = 'ad'
   - Call getAccountInsights()
   - If adId provided, filter to matching ad
   - Parse and format response (ad ID, ad name if available, metrics)
   - Return JSON.stringify(result, null, 2)

Response format note: Individual ads may not have ad_name field (use ad_id instead). Handle gracefully.

Error handling:
- Same pattern as Task 1
- "No ads found for date range" if empty
- "Ad {id} not found" if adId specified but missing

Why this approach: Ad level is the most granular, shows individual creative performance. Level='ad' aggregation documented in DISCOVERY.md Section "Meta Insights API Structure".

What to avoid: Don't fetch creative assets (images/videos) - just performance metrics. That's outside Phase 2 scope.
  </action>
  <verify>npm run type-check passes, ad level queries work, handles missing ad_name field</verify>
  <done>Ad performance tool created, follows established patterns, granular creative metrics queryable</done>
</task>

<task type="auto">
  <name>Task 3: Register both tools in MCP server</name>
  <files>src/tools/index.ts, src/index.ts</files>
  <action>
Integrate both new tools into MCP server, following 02-02 registration pattern.

In src/tools/index.ts:
1. Import getAdsetPerformanceTool from './get-adset-performance.js'
2. Import getAdPerformanceTool from './get-ad-performance.js'
3. Add to tools array (now 4 tools total):
   ```typescript
   export const tools: Tool[] = [
     getAccountTool,
     getCampaignPerformanceTool,
     getAdsetPerformanceTool,
     getAdPerformanceTool
   ];
   ```

In src/index.ts:
1. Import getAdsetPerformance from './tools/get-adset-performance.js'
2. Import getAdPerformance from './tools/get-ad-performance.js'
3. Add cases to CallToolRequestSchema handler:
   ```typescript
   case 'get-adset-performance': {
     const result = await getAdsetPerformance(args as any);
     return { content: [{ type: 'text', text: result }] };
   }
   case 'get-ad-performance': {
     const result = await getAdPerformance(args as any);
     return { content: [{ type: 'text', text: result }] };
   }
   ```

Verification:
- npm run build succeeds
- npm run dev starts without errors
- Server logs "Meta Ads MCP server started successfully"
- 4 tools discoverable via MCP protocol

Why this pattern: Consistent with Phase 1 and 02-02 registration. Each tool independently discoverable and callable.

What to avoid: Don't forget .js extensions in imports. Don't modify existing tool handlers.
  </action>
  <verify>npm run build && npm run dev starts successfully, 4 tools registered, no TypeScript errors</verify>
  <done>Both tools registered, server starts without crashes, all 4 performance query tools operational</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] npm run build succeeds with no TypeScript errors
- [ ] npm run dev starts server without crashes
- [ ] Tools registry shows 4 tools (get-account, get-campaign-performance, get-adset-performance, get-ad-performance)
- [ ] All tools follow consistent pattern and response format
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Phase 2 complete: All aggregation levels queryable (account, campaign, adset, ad)
- Core metrics accessible through MCP for conversational ad analysis
- Foundation ready for Phase 3 (video analytics with breakdowns)
- No TypeScript errors or runtime crashes
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-metrics-query/02-03-SUMMARY.md`:

# Phase 2 Plan 03: Ad Set and Ad Level Queries Summary

**[Substantive one-liner - what shipped, not "phase complete"]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `path/to/file.ts` - Description
- `path/to/another.ts` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Deviations from Plan

[Any deviations using deviation rules, or "None"]

## Next Phase Readiness

Phase 2 complete! Ready for Phase 3: Video Analytics.

All four aggregation levels (account, campaign, adset, ad) now queryable through MCP. Core metrics foundation enables conversational ad performance analysis. Next phase will add video-specific metrics and demographic breakdowns.

## Verification Checklist

- [ ] All verification items from plan
</output>
